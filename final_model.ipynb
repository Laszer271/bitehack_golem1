{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['anger', 'joy', 'optimism', 'sadness', 'not-hate', 'hate', 'non_irony', 'not-offensive', 'offensive',\n",
    "               'negative', 'neutral', 'positive', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>0.195406</td>\n",
       "      <td>0.677751</td>\n",
       "      <td>0.983329</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>0.757905</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.438617</td>\n",
       "      <td>0.422358</td>\n",
       "      <td>0.139025</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.921817</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.334317</td>\n",
       "      <td>0.919669</td>\n",
       "      <td>0.073009</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.905163</td>\n",
       "      <td>0.978436</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.992365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.933811</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>0.948829</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>0.969039</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976041</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.206814</td>\n",
       "      <td>0.432330</td>\n",
       "      <td>0.419770</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>0.909924</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0  0.115456  0.011387  0.195406  0.677751  0.983329  0.016671   0.849077   \n",
       "1  0.966903  0.006743  0.005363  0.020991  0.909270  0.090730   0.921817   \n",
       "2  0.009321  0.957922  0.016562  0.016195  0.972480  0.027520   0.905163   \n",
       "3  0.008275  0.959311  0.019986  0.012427  0.933811  0.066188   0.948829   \n",
       "4  0.976041  0.004920  0.011711  0.007327  0.793186  0.206814   0.432330   \n",
       "\n",
       "   not-offensive  offensive  negative   neutral  positive         label  \n",
       "0       0.757905   0.242095  0.438617  0.422358  0.139025         happy  \n",
       "1       0.665683   0.334317  0.919669  0.073009  0.007322         angry  \n",
       "2       0.978436   0.021564  0.001311  0.006323  0.992365         happy  \n",
       "3       0.909642   0.090358  0.001438  0.029523  0.969039         happy  \n",
       "4       0.419770   0.580230  0.909924  0.083572  0.006504  disappointed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('dataset_preds_all_models_train.csv')[cols_to_drop]#.drop(columns=cols_to_drop)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.965951</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.974149</td>\n",
       "      <td>0.025850</td>\n",
       "      <td>0.849865</td>\n",
       "      <td>0.977916</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.991595</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899331</td>\n",
       "      <td>0.053033</td>\n",
       "      <td>0.036412</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.774592</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.795617</td>\n",
       "      <td>0.874663</td>\n",
       "      <td>0.125337</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.604198</td>\n",
       "      <td>0.156686</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282376</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>0.047360</td>\n",
       "      <td>0.927542</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.968107</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.183343</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>0.488834</td>\n",
       "      <td>0.343542</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.952730</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.959886</td>\n",
       "      <td>0.040114</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.952512</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.981497</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.970835</td>\n",
       "      <td>0.029165</td>\n",
       "      <td>0.952927</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.991798</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0  0.008511  0.965951  0.013212  0.012326  0.974149  0.025850   0.849865   \n",
       "1  0.899331  0.053033  0.036412  0.011225  0.774592  0.225408   0.795617   \n",
       "2  0.282376  0.043560  0.626704  0.047360  0.927542  0.072458   0.968107   \n",
       "3  0.011135  0.952730  0.022653  0.013482  0.959886  0.040114   0.952556   \n",
       "4  0.007975  0.968310  0.012793  0.010921  0.970835  0.029165   0.952927   \n",
       "\n",
       "   not-offensive  offensive  negative   neutral  positive  label  \n",
       "0       0.977916   0.022084  0.001440  0.006966  0.991595  happy  \n",
       "1       0.874663   0.125337  0.239116  0.604198  0.156686  angry  \n",
       "2       0.816657   0.183343  0.167623  0.488834  0.343542  happy  \n",
       "3       0.952512   0.047487  0.000974  0.017529  0.981497  happy  \n",
       "4       0.974449   0.025551  0.001060  0.007141  0.991798  happy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('dataset_preds_all_models_test.csv')[cols_to_drop]#.drop(columns=cols_to_drop)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'joy', 'optimism', 'sadness', 'not-hate', 'hate', 'non_irony',\n",
       "       'not-offensive', 'offensive', 'negative', 'neutral', 'positive',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 13) (74, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 12) (294,) (294, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns='label')\n",
    "y_train = df_train['label']\n",
    "print(X_train.shape, y_train.shape, df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 12) (74,) (74, 13)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(columns='label')\n",
    "y_test = df_test['label']\n",
    "print(X_test.shape, y_test.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(pd.DataFrame(y_train))\n",
    "y_train_enc = encoder.transform(pd.DataFrame(y_train)).toarray()\n",
    "y_test_enc = encoder.transform(pd.DataFrame(y_test)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(X_train.shape[1]))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', metrics=['acc'], loss='bce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6142 - acc: 0.3503 - val_loss: 0.5379 - val_acc: 0.5135\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5211 - acc: 0.4694 - val_loss: 0.4881 - val_acc: 0.5405\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4843 - acc: 0.4932 - val_loss: 0.4651 - val_acc: 0.5811\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4577 - acc: 0.5102 - val_loss: 0.4459 - val_acc: 0.6622\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4413 - acc: 0.5238 - val_loss: 0.4259 - val_acc: 0.6757\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4467 - acc: 0.5408 - val_loss: 0.4121 - val_acc: 0.6622\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4353 - acc: 0.5170 - val_loss: 0.4067 - val_acc: 0.6622\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4323 - acc: 0.5476 - val_loss: 0.3992 - val_acc: 0.6622\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4300 - acc: 0.5408 - val_loss: 0.3974 - val_acc: 0.6892\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4364 - acc: 0.5476 - val_loss: 0.3973 - val_acc: 0.6892\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4170 - acc: 0.5680 - val_loss: 0.3956 - val_acc: 0.6622\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4382 - acc: 0.5442 - val_loss: 0.3999 - val_acc: 0.6892\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4329 - acc: 0.5510 - val_loss: 0.4041 - val_acc: 0.6486\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4363 - acc: 0.5034 - val_loss: 0.3983 - val_acc: 0.6757\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4377 - acc: 0.5476 - val_loss: 0.3993 - val_acc: 0.6757\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4353 - acc: 0.5306 - val_loss: 0.4013 - val_acc: 0.6892\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4250 - acc: 0.5544 - val_loss: 0.4006 - val_acc: 0.6757\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4457 - acc: 0.5340 - val_loss: 0.3997 - val_acc: 0.6757\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4430 - acc: 0.5646 - val_loss: 0.4023 - val_acc: 0.6757\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4056 - acc: 0.5986 - val_loss: 0.4051 - val_acc: 0.6757\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4182 - acc: 0.5816 - val_loss: 0.4041 - val_acc: 0.6486\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4329 - acc: 0.5578 - val_loss: 0.4070 - val_acc: 0.6486\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4395 - acc: 0.5510 - val_loss: 0.4036 - val_acc: 0.6486\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4253 - acc: 0.5646 - val_loss: 0.4023 - val_acc: 0.6622\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4150 - acc: 0.5884 - val_loss: 0.4119 - val_acc: 0.6486\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4366 - acc: 0.5408 - val_loss: 0.4159 - val_acc: 0.6486\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4069 - acc: 0.5748 - val_loss: 0.4102 - val_acc: 0.6486\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4167 - acc: 0.5544 - val_loss: 0.4139 - val_acc: 0.6486\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4342 - acc: 0.5374 - val_loss: 0.4164 - val_acc: 0.6486\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4054 - acc: 0.5952 - val_loss: 0.4172 - val_acc: 0.6216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebdc025cf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_enc,\n",
    "          validation_data=(X_test, y_test_enc),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4172 - acc: 0.6216\n"
     ]
    }
   ],
   "source": [
    "x = model.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6216216087341309\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\__repos\\bitehack_golem1\\final_model.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__repos/bitehack_golem1/final_model.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(X_test\u001b[39m.\u001b[39;49mtoarray()), \u001b[39mtype\u001b[39m(y_test_enc))\n",
      "File \u001b[1;32md:\\__repos\\bitehack_golem1\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5567'>5568</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5568'>5569</a>\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5569'>5570</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5570'>5571</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5571'>5572</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5572'>5573</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5573'>5574</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> <a href='file:///d%3A/__repos/bitehack_golem1/venv/lib/site-packages/pandas/core/generic.py?line=5574'>5575</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "print(type(X_test.toarray()), type(y_test_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>0.195406</td>\n",
       "      <td>0.677751</td>\n",
       "      <td>0.983329</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>0.757905</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.438617</td>\n",
       "      <td>0.422358</td>\n",
       "      <td>0.139025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.921817</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.334317</td>\n",
       "      <td>0.919669</td>\n",
       "      <td>0.073009</td>\n",
       "      <td>0.007322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.905163</td>\n",
       "      <td>0.978436</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.992365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.933811</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>0.948829</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>0.969039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976041</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.206814</td>\n",
       "      <td>0.432330</td>\n",
       "      <td>0.419770</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>0.909924</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.006504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.946807</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.026562</td>\n",
       "      <td>0.973105</td>\n",
       "      <td>0.026895</td>\n",
       "      <td>0.574206</td>\n",
       "      <td>0.783511</td>\n",
       "      <td>0.216489</td>\n",
       "      <td>0.718968</td>\n",
       "      <td>0.251746</td>\n",
       "      <td>0.029286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.976294</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.855168</td>\n",
       "      <td>0.144832</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.298030</td>\n",
       "      <td>0.701970</td>\n",
       "      <td>0.910729</td>\n",
       "      <td>0.080216</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.941383</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.873737</td>\n",
       "      <td>0.126263</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.837171</td>\n",
       "      <td>0.162829</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>0.257857</td>\n",
       "      <td>0.037348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.965446</td>\n",
       "      <td>0.950855</td>\n",
       "      <td>0.049145</td>\n",
       "      <td>0.680607</td>\n",
       "      <td>0.834669</td>\n",
       "      <td>0.165331</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>0.481803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.962654</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.961703</td>\n",
       "      <td>0.038297</td>\n",
       "      <td>0.861514</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>0.410796</td>\n",
       "      <td>0.963854</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0    0.115456  0.011387  0.195406  0.677751  0.983329  0.016671   0.849077   \n",
       "1    0.966903  0.006743  0.005363  0.020991  0.909270  0.090730   0.921817   \n",
       "2    0.009321  0.957922  0.016562  0.016195  0.972480  0.027520   0.905163   \n",
       "3    0.008275  0.959311  0.019986  0.012427  0.933811  0.066188   0.948829   \n",
       "4    0.976041  0.004920  0.011711  0.007327  0.793186  0.206814   0.432330   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "289  0.946807  0.006391  0.020240  0.026562  0.973105  0.026895   0.574206   \n",
       "290  0.976294  0.006404  0.011243  0.006058  0.855168  0.144832   0.364300   \n",
       "291  0.941383  0.006008  0.016589  0.036020  0.873737  0.126263   0.574084   \n",
       "292  0.014331  0.005081  0.015142  0.965446  0.950855  0.049145   0.680607   \n",
       "293  0.962654  0.007575  0.008550  0.021221  0.961703  0.038297   0.861514   \n",
       "\n",
       "     not-offensive  offensive  negative   neutral  positive  \n",
       "0         0.757905   0.242095  0.438617  0.422358  0.139025  \n",
       "1         0.665683   0.334317  0.919669  0.073009  0.007322  \n",
       "2         0.978436   0.021564  0.001311  0.006323  0.992365  \n",
       "3         0.909642   0.090358  0.001438  0.029523  0.969039  \n",
       "4         0.419770   0.580230  0.909924  0.083572  0.006504  \n",
       "..             ...        ...       ...       ...       ...  \n",
       "289       0.783511   0.216489  0.718968  0.251746  0.029286  \n",
       "290       0.298030   0.701970  0.910729  0.080216  0.009055  \n",
       "291       0.837171   0.162829  0.704795  0.257857  0.037348  \n",
       "292       0.834669   0.165331  0.057824  0.460373  0.481803  \n",
       "293       0.589204   0.410796  0.963854  0.031345  0.004801  \n",
       "\n",
       "[294 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32ec92d42e089a7c7533d97c7987edf4a4ef319c10bc9c0c9173583b36498dcf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
