{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['anger', 'joy', 'optimism', 'sadness', 'not-hate', 'hate', 'non_irony', 'not-offensive', 'offensive',\n",
    "               'negative', 'neutral', 'positive', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'joy', 'optimism', 'sadness', 'not-hate', 'hate', 'non_irony',\n",
       "       'not-offensive', 'offensive', 'negative', 'neutral', 'positive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>0.195406</td>\n",
       "      <td>0.677751</td>\n",
       "      <td>0.983329</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>0.757905</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.438617</td>\n",
       "      <td>0.422358</td>\n",
       "      <td>0.139025</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.921817</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.334317</td>\n",
       "      <td>0.919669</td>\n",
       "      <td>0.073009</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.905163</td>\n",
       "      <td>0.978436</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.992365</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.933811</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>0.948829</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>0.969039</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976041</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.206814</td>\n",
       "      <td>0.432330</td>\n",
       "      <td>0.419770</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>0.909924</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0  0.115456  0.011387  0.195406  0.677751  0.983329  0.016671   0.849077   \n",
       "1  0.966903  0.006743  0.005363  0.020991  0.909270  0.090730   0.921817   \n",
       "2  0.009321  0.957922  0.016562  0.016195  0.972480  0.027520   0.905163   \n",
       "3  0.008275  0.959311  0.019986  0.012427  0.933811  0.066188   0.948829   \n",
       "4  0.976041  0.004920  0.011711  0.007327  0.793186  0.206814   0.432330   \n",
       "\n",
       "   not-offensive  offensive  negative   neutral  positive         label  \n",
       "0       0.757905   0.242095  0.438617  0.422358  0.139025         happy  \n",
       "1       0.665683   0.334317  0.919669  0.073009  0.007322         angry  \n",
       "2       0.978436   0.021564  0.001311  0.006323  0.992365         happy  \n",
       "3       0.909642   0.090358  0.001438  0.029523  0.969039         happy  \n",
       "4       0.419770   0.580230  0.909924  0.083572  0.006504  disappointed  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('dataset_preds_all_models_train.csv')[cols_to_drop]#.drop(columns=cols_to_drop)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.965951</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.974149</td>\n",
       "      <td>0.025850</td>\n",
       "      <td>0.849865</td>\n",
       "      <td>0.977916</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.991595</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899331</td>\n",
       "      <td>0.053033</td>\n",
       "      <td>0.036412</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.774592</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.795617</td>\n",
       "      <td>0.874663</td>\n",
       "      <td>0.125337</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.604198</td>\n",
       "      <td>0.156686</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282376</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>0.047360</td>\n",
       "      <td>0.927542</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.968107</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.183343</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>0.488834</td>\n",
       "      <td>0.343542</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.952730</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.959886</td>\n",
       "      <td>0.040114</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.952512</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.981497</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.970835</td>\n",
       "      <td>0.029165</td>\n",
       "      <td>0.952927</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.991798</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0  0.008511  0.965951  0.013212  0.012326  0.974149  0.025850   0.849865   \n",
       "1  0.899331  0.053033  0.036412  0.011225  0.774592  0.225408   0.795617   \n",
       "2  0.282376  0.043560  0.626704  0.047360  0.927542  0.072458   0.968107   \n",
       "3  0.011135  0.952730  0.022653  0.013482  0.959886  0.040114   0.952556   \n",
       "4  0.007975  0.968310  0.012793  0.010921  0.970835  0.029165   0.952927   \n",
       "\n",
       "   not-offensive  offensive  negative   neutral  positive  label  \n",
       "0       0.977916   0.022084  0.001440  0.006966  0.991595  happy  \n",
       "1       0.874663   0.125337  0.239116  0.604198  0.156686  angry  \n",
       "2       0.816657   0.183343  0.167623  0.488834  0.343542  happy  \n",
       "3       0.952512   0.047487  0.000974  0.017529  0.981497  happy  \n",
       "4       0.974449   0.025551  0.001060  0.007141  0.991798  happy  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('dataset_preds_all_models_test.csv')[cols_to_drop]#.drop(columns=cols_to_drop)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anger', 'joy', 'optimism', 'sadness', 'not-hate', 'hate', 'non_irony',\n",
       "       'not-offensive', 'offensive', 'negative', 'neutral', 'positive',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 13) (74, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 12) (294,) (294, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns='label')\n",
    "y_train = df_train['label']\n",
    "print(X_train.shape, y_train.shape, df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 12) (74,) (74, 13)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(columns='label')\n",
    "y_test = df_test['label']\n",
    "print(X_test.shape, y_test.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(pd.DataFrame(y_train))\n",
    "y_train_enc = encoder.transform(pd.DataFrame(y_train)).toarray()\n",
    "y_test_enc = encoder.transform(pd.DataFrame(y_test)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(X_train.shape[1]))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', metrics=['acc'], loss='bce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 16ms/step - loss: 0.6074 - acc: 0.3401 - val_loss: 0.5354 - val_acc: 0.5405\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5174 - acc: 0.4932 - val_loss: 0.4844 - val_acc: 0.5270\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4801 - acc: 0.5510 - val_loss: 0.4573 - val_acc: 0.6757\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4604 - acc: 0.5748 - val_loss: 0.4385 - val_acc: 0.6757\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4476 - acc: 0.5408 - val_loss: 0.4251 - val_acc: 0.6757\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4230 - acc: 0.5748 - val_loss: 0.4125 - val_acc: 0.6622\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4166 - acc: 0.5850 - val_loss: 0.4094 - val_acc: 0.6622\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4353 - acc: 0.5272 - val_loss: 0.4054 - val_acc: 0.6892\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4230 - acc: 0.5374 - val_loss: 0.4016 - val_acc: 0.6622\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4318 - acc: 0.5374 - val_loss: 0.4034 - val_acc: 0.6892\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4407 - acc: 0.5306 - val_loss: 0.4057 - val_acc: 0.6757\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4219 - acc: 0.5374 - val_loss: 0.4020 - val_acc: 0.6892\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4182 - acc: 0.5578 - val_loss: 0.4031 - val_acc: 0.6622\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4171 - acc: 0.5748 - val_loss: 0.4055 - val_acc: 0.6892\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4187 - acc: 0.5442 - val_loss: 0.4007 - val_acc: 0.6892\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4123 - acc: 0.5782 - val_loss: 0.3995 - val_acc: 0.6622\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4475 - acc: 0.5442 - val_loss: 0.3985 - val_acc: 0.6486\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4126 - acc: 0.5476 - val_loss: 0.4005 - val_acc: 0.6757\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4361 - acc: 0.5374 - val_loss: 0.4054 - val_acc: 0.6757\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4316 - acc: 0.5510 - val_loss: 0.4035 - val_acc: 0.6757\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4056 - acc: 0.5816 - val_loss: 0.4001 - val_acc: 0.6757\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4209 - acc: 0.5612 - val_loss: 0.4010 - val_acc: 0.6486\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4209 - acc: 0.5340 - val_loss: 0.4118 - val_acc: 0.6216\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4154 - acc: 0.5680 - val_loss: 0.4044 - val_acc: 0.6892\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4324 - acc: 0.5646 - val_loss: 0.4030 - val_acc: 0.6486\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4035 - acc: 0.5918 - val_loss: 0.4045 - val_acc: 0.6486\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4158 - acc: 0.5544 - val_loss: 0.4070 - val_acc: 0.6486\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4287 - acc: 0.5510 - val_loss: 0.4138 - val_acc: 0.6081\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4241 - acc: 0.5374 - val_loss: 0.4090 - val_acc: 0.6486\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4127 - acc: 0.5442 - val_loss: 0.4072 - val_acc: 0.6486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c5d9d0fd0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_enc,\n",
    "          validation_data=(X_test, y_test_enc),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4072 - acc: 0.6486\n"
     ]
    }
   ],
   "source": [
    "x = model.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6486486196517944\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-45b97cfc57a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_enc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "print(type(X_test.toarray()), type(y_test_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>non_irony</th>\n",
       "      <th>irony</th>\n",
       "      <th>not-offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>im_angry</th>\n",
       "      <th>im_disgust</th>\n",
       "      <th>im_fear</th>\n",
       "      <th>im_happy</th>\n",
       "      <th>im_sad</th>\n",
       "      <th>im_surprise</th>\n",
       "      <th>im_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>0.195406</td>\n",
       "      <td>0.677751</td>\n",
       "      <td>0.983329</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>0.150923</td>\n",
       "      <td>0.757905</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.909270</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.921817</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.334317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134106</td>\n",
       "      <td>0.529002</td>\n",
       "      <td>0.076143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.905163</td>\n",
       "      <td>0.094837</td>\n",
       "      <td>0.978436</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055007</td>\n",
       "      <td>0.763734</td>\n",
       "      <td>0.035462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.933811</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>0.948829</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976041</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.206814</td>\n",
       "      <td>0.432330</td>\n",
       "      <td>0.567670</td>\n",
       "      <td>0.419770</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.946807</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.026562</td>\n",
       "      <td>0.973105</td>\n",
       "      <td>0.026895</td>\n",
       "      <td>0.574206</td>\n",
       "      <td>0.425794</td>\n",
       "      <td>0.783511</td>\n",
       "      <td>0.216489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.976294</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.855168</td>\n",
       "      <td>0.144832</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.298030</td>\n",
       "      <td>0.701970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.941383</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.873737</td>\n",
       "      <td>0.126263</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.425916</td>\n",
       "      <td>0.837171</td>\n",
       "      <td>0.162829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.965446</td>\n",
       "      <td>0.950855</td>\n",
       "      <td>0.049145</td>\n",
       "      <td>0.680607</td>\n",
       "      <td>0.319393</td>\n",
       "      <td>0.834669</td>\n",
       "      <td>0.165331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.962654</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.961703</td>\n",
       "      <td>0.038297</td>\n",
       "      <td>0.861514</td>\n",
       "      <td>0.138487</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>0.410796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210257</td>\n",
       "      <td>0.325394</td>\n",
       "      <td>0.134980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        anger       joy  optimism   sadness  not-hate      hate  non_irony  \\\n",
       "0    0.115456  0.011387  0.195406  0.677751  0.983329  0.016671   0.849077   \n",
       "1    0.966903  0.006743  0.005363  0.020991  0.909270  0.090730   0.921817   \n",
       "2    0.009321  0.957922  0.016562  0.016195  0.972480  0.027520   0.905163   \n",
       "3    0.008275  0.959311  0.019986  0.012427  0.933811  0.066188   0.948829   \n",
       "4    0.976041  0.004920  0.011711  0.007327  0.793186  0.206814   0.432330   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "289  0.946807  0.006391  0.020240  0.026562  0.973105  0.026895   0.574206   \n",
       "290  0.976294  0.006404  0.011243  0.006058  0.855168  0.144832   0.364300   \n",
       "291  0.941383  0.006008  0.016589  0.036020  0.873737  0.126263   0.574084   \n",
       "292  0.014331  0.005081  0.015142  0.965446  0.950855  0.049145   0.680607   \n",
       "293  0.962654  0.007575  0.008550  0.021221  0.961703  0.038297   0.861514   \n",
       "\n",
       "        irony  not-offensive  offensive  ...         1         2         3  \\\n",
       "0    0.150923       0.757905   0.242095  ...  0.000000  0.000000  0.000000   \n",
       "1    0.078183       0.665683   0.334317  ...  0.134106  0.529002  0.076143   \n",
       "2    0.094837       0.978436   0.021564  ...  0.055007  0.763734  0.035462   \n",
       "3    0.051171       0.909642   0.090358  ...  0.000000  0.000000  0.000000   \n",
       "4    0.567670       0.419770   0.580230  ...  0.000000  0.000000  0.000000   \n",
       "..        ...            ...        ...  ...       ...       ...       ...   \n",
       "289  0.425794       0.783511   0.216489  ...  0.000000  0.000000  0.000000   \n",
       "290  0.635700       0.298030   0.701970  ...  0.000000  0.000000  0.000000   \n",
       "291  0.425916       0.837171   0.162829  ...  0.000000  0.000000  0.000000   \n",
       "292  0.319393       0.834669   0.165331  ...  0.000000  0.000000  0.000000   \n",
       "293  0.138487       0.589204   0.410796  ...  0.210257  0.325394  0.134980   \n",
       "\n",
       "     im_angry  im_disgust  im_fear  im_happy  im_sad  im_surprise  im_neutral  \n",
       "0         0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "1         0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "2         0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "3         0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "4         0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "..        ...         ...      ...       ...     ...          ...         ...  \n",
       "289       0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "290       0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "291       0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "292       0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "293       0.0         0.0      0.0       0.0     0.0          0.0         0.0  \n",
       "\n",
       "[294 rows x 37 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "444ccfdd9b7cd673cafd72416c5b635912c8cda90bd0d6dd0d8d3fb871268130"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
