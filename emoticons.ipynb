{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.Text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emot\n",
    "\n",
    "emot_obj = emot.core.emot()\n",
    "text = \"I love python ‚òÆ üôÇ ‚ù§ :-) :-( :-)))\"\n",
    "print(emot_obj.emoji(text)[\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "def f(dict, path):\n",
    "    path = os.path.join(path, dict)\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "path = os.path.join(\"emoji_data\")\n",
    "files = os.listdir(path)\n",
    "loaded_dicts = [f(file, path) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics_names = [\n",
    "    \"EMOJI_UNICODE\",\n",
    "    \"UNICODE_EMOJI\",\n",
    "    \"EMOJI_ALIAS_UNICODE\",\n",
    "    \"UNICODE_EMOJI_ALIAS\",\n",
    "    \"EMOTICONS_EMO\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_val = []\n",
    "for text in texts:\n",
    "    if emot_obj.emoji(text)[\"flag\"]:\n",
    "        val = emot_obj.emoji(text)[\"value\"]\n",
    "        text_val.append([text, val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos = emot_obj.emoji(text)[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(loaded_dicts[2].keys()).index(list(loaded_dicts[2].keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(loaded_dicts[2].keys())\n",
    "in_test_emo = keys[0:7]\n",
    "in_test_emo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys.index(in_test_emo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(list(loaded_dicts[2].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indeces(columns, values):\n",
    "    columns = columns.flatten()\n",
    "    inds = np.array([np.where(columns == searchval)[0] for searchval in values]).flatten()\n",
    "    return inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = find_indeces(keys, in_test_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((2,keys.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros[0][inds] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = emot_obj.emoji(text)[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros[0][find_indeces(keys, vals)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_extraced = [emot_obj.emoji(text)[\"value\"] for text in texts if emot_obj.emoji(text)[\"flag\"]]\n",
    "training_len = len(emojis_extraced)\n",
    "encoded = np.zeros((training_len,keys.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, emojis in zip(encoded, emojis_extraced):\n",
    "    row[find_indeces(keys,emojis)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memoi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      3\u001b[0m dropped_empty \u001b[38;5;241m=\u001b[39m main[main\u001b[38;5;241m.\u001b[39memoi \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "main = pd.read_csv(\"dataset_.csv\")[[\"emoi\",\"label\"]]\n",
    "\n",
    "dropped_empty = main[main.emoi != \"[]\"]\n",
    "import ast\n",
    "dropped_empty['emoi']=dropped_empty['emoi'].apply(ast.literal_eval)\n",
    "emojis_set = dropped_empty.emoi.to_list()\n",
    "encoded = np.zeros((len(emojis_set),keys.shape[0]))\n",
    "for row, emojis in zip(encoded, emojis_set):\n",
    "    row[find_indeces(keys,emojis)] = 1\n",
    "encoded_df = pd.DataFrame(encoded)\n",
    "dropped_empty.reset_index(drop=True, inplace=True)\n",
    "dropped_empty.index\n",
    "merged = dropped_empty.join(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "444ccfdd9b7cd673cafd72416c5b635912c8cda90bd0d6dd0d8d3fb871268130"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
