{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ubNhxIpo9FIP"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import math\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aKrG7tAj9Gya"
   },
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V0bl5XC39IYE"
   },
   "outputs": [],
   "source": [
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "tasks = ['emotion', 'hate', 'irony', 'offensive', 'sentiment']\n",
    "model_paths = []\n",
    "\n",
    "for task in tasks:\n",
    "  model_path = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "  model_paths.append(model_path)\n",
    "    \n",
    "model_mapping = {task: model_paths[i] for i, task in enumerate(tasks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cardiffnlp/twitter-roberta-base-emotion', 'cardiffnlp/twitter-roberta-base-hate', 'cardiffnlp/twitter-roberta-base-irony', 'cardiffnlp/twitter-roberta-base-offensive', 'cardiffnlp/twitter-roberta-base-sentiment']\n"
     ]
    }
   ],
   "source": [
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2H1nhuQ-XnY"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DTGHEM1c-W8s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rGdydRZ47jQr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_.csv')\n",
    "df = df[['Text', 'label', 'emoi', 'hashtags', 'Media URLs']]\n",
    "df = df.sample(frac=0.02)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BJqzvjR8_RY4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['label']\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "X_train = df_train['Text']\n",
    "X_test = df_test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>emoi</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Media URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @FranticKL : This is truly sad and most unk...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@imVkohli Sad to get this news but you are rhe...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad don't touch me https://t.co/ayNqChhXmP...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJKQ1AlXIAMujwA.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AshaRangappa_ : STEP 5: Plan for all of th...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @_EL_PsyCongroo_ : #GenshinImpact #zhongxia...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[]</td>\n",
       "      <td>['GenshinImpact', 'zhongxiao', 'ÈçæÈ≠à']</td>\n",
       "      <td>https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label emoi  \\\n",
       "0  RT @FranticKL : This is truly sad and most unk...    sad   []   \n",
       "1  @imVkohli Sad to get this news but you are rhe...    sad   []   \n",
       "2  I'm sad don't touch me https://t.co/ayNqChhXmP...    sad   []   \n",
       "3  RT @AshaRangappa_ : STEP 5: Plan for all of th...  angry   []   \n",
       "4  RT @_EL_PsyCongroo_ : #GenshinImpact #zhongxia...  angry   []   \n",
       "\n",
       "                               hashtags  \\\n",
       "0                                    []   \n",
       "1                                    []   \n",
       "2                                    []   \n",
       "3                                    []   \n",
       "4  ['GenshinImpact', 'zhongxiao', 'ÈçæÈ≠à']   \n",
       "\n",
       "                                        Media URLs  \n",
       "0  https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg  \n",
       "1                                              NaN  \n",
       "2  https://pbs.twimg.com/media/FJKQ1AlXIAMujwA.jpg  \n",
       "3  https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg  \n",
       "4  https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from tensorflow import keras\n",
    "hashtags = df_train['hashtags'].str.strip('[]').str.replace(\"'\", '').str.lower()\n",
    "\n",
    "emojis = df_train['emoi'].str.strip('[]').str.replace(\"'\", '').str.lower()\n",
    "emoticons_model = keras.models.load_model('emoticons.h5')\n",
    "\n",
    "images = df_train['Media URLs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117,) == (117,)\n"
     ]
    }
   ],
   "source": [
    "print(hashtags.shape, '==', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "q5fytnTxkhqh"
   },
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, preprocess, X, emb_max_size=512):\n",
    "  X = X.apply(preprocess)\n",
    "  encoded_input = tokenizer(X.to_list(), return_tensors='pt', padding=True)\n",
    "  encoded_input['input_ids'] = encoded_input['input_ids'][:, :emb_max_size]\n",
    "  encoded_input['attention_mask'] = encoded_input['attention_mask'][:, :emb_max_size]\n",
    "\n",
    "  output = model(**encoded_input)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel:\n",
    "    def __init__(self, model_path_mapping, batch_size=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.model_path_mapping = model_path_mapping\n",
    "    \n",
    "    def predict(self, X, tasks_list, prefix='', verbose=1):\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        for i, task in enumerate(tasks_list):\n",
    "            print('X:', X.shape)\n",
    "            if verbose:\n",
    "                print(f'Step {i}/{len(tasks_list)}, Task: {task}')\n",
    "            model_path = self.model_path_mapping[task]\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            tokenizer.save_pretrained(model_path)\n",
    "            model.save_pretrained(model_path) \n",
    "            \n",
    "            labels=[]\n",
    "            mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "            with urllib.request.urlopen(mapping_link) as f:\n",
    "                html = f.read().decode('utf-8').split(\"\\n\")\n",
    "                csvreader = csv.reader(html, delimiter='\\t')\n",
    "            labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "            \n",
    "            outputs = []\n",
    "            n_batches = math.ceil(X.shape[0] / self.batch_size)\n",
    "            for i in range(n_batches):\n",
    "                if verbose > 1:\n",
    "                    print(i, '/', n_batches)\n",
    "                x = X[i*self.batch_size: (i+1)*self.batch_size]\n",
    "\n",
    "                out = predict(model, tokenizer, preprocess, x)\n",
    "                out['logits'] = out['logits'].cpu().detach()\n",
    "                outputs.append(out)\n",
    "                \n",
    "            output = {}\n",
    "            output['logits'] = torch.cat([out['logits'] for out in outputs], axis=0)\n",
    "            \n",
    "            scores = output['logits'].detach().numpy()\n",
    "            scores = softmax(scores, axis=1)\n",
    "            if verbose:\n",
    "                print('Output shape:', scores.shape)\n",
    "            \n",
    "            for i in range(scores.shape[1]):\n",
    "                label = labels[i]\n",
    "                df[prefix + label] = scores[:, i]\n",
    "        return df\n",
    "\n",
    "class HashtagModel(TextModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def predict(self, X, *args, **kwargs):\n",
    "        mask = X.str.len() == 0\n",
    "        df = super().predict(X, *args, **kwargs)\n",
    "        print(mask.shape, df.shape)\n",
    "        df.loc[mask, :] = 0.0\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (117,)\n",
      "Step 0/5, Task: emotion\n",
      "Output shape: (117, 4)\n",
      "X: (117,)\n",
      "Step 1/5, Task: hate\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 2/5, Task: irony\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 3/5, Task: offensive\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 4/5, Task: sentiment\n",
      "Output shape: (117, 3)\n"
     ]
    }
   ],
   "source": [
    "text_model = TextModel(model_mapping)\n",
    "text_preds = text_model.predict(X_train, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (117,)\n",
      "Step 0/5, Task: emotion\n",
      "Output shape: (117, 4)\n",
      "X: (117,)\n",
      "Step 1/5, Task: hate\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 2/5, Task: irony\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 3/5, Task: offensive\n",
      "Output shape: (117, 2)\n",
      "X: (117,)\n",
      "Step 4/5, Task: sentiment\n",
      "Output shape: (117, 3)\n",
      "(117,) (117, 13)\n"
     ]
    }
   ],
   "source": [
    "hashtag_model = HashtagModel(model_mapping)\n",
    "hashtag_preds = hashtag_model.predict(hashtags, tasks, prefix='hm_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import os\n",
    "import ast\n",
    "\n",
    "class EmojiModel():\n",
    "    def __init__(self, emoji_data_path, optimizer='adam', loss='bce', metrics=None):\n",
    "        \n",
    "        with open(emoji_data_path, 'rb') as f:\n",
    "            self.emoji_data =  pickle.load(f)\n",
    "        self.keys = np.array(list(self.emoji_data.keys()))\n",
    "        \n",
    "        if metrics is None:\n",
    "            metrics = ['acc']\n",
    "\n",
    "        self.model = self.build_model(optimizer, loss, metrics)\n",
    "        self.encoder = None \n",
    "        self.categories = None\n",
    "        \n",
    "    def build_model(self, optimizer, loss, metrics):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Input((len(self.keys),)))\n",
    "        model.add(keras.layers.Dropout(0.5))\n",
    "        model.add(keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.5))\n",
    "        model.add(keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, metrics=metrics, loss=loss)\n",
    "        return model\n",
    "    \n",
    "    def preprocess(self, X):\n",
    "        X = X.str.split(', ')\n",
    "        mask = X.map(lambda d: len(d) > 2 or (len(d) == 1 and d[0] != '' and d[0] != ' '))\n",
    "        encoded = np.zeros((len(X), self.keys.shape[0]))\n",
    "        \n",
    "        for i, x in enumerate(X):\n",
    "            if mask[i]:\n",
    "                idx = self._find_indices(x)\n",
    "                if len(idx) > 0:\n",
    "                    encoded[i, idx] = 1\n",
    "            \n",
    "        return encoded\n",
    "    \n",
    "    def fit(self, X, y, *args, validation_data=None, **kwargs):\n",
    "        mask = X.str.split(', ').map(lambda d: len(d) > 2 or (len(d) == 1 and d[0] != '' and d[0] != ' '))\n",
    "        X = self.preprocess(X)\n",
    "        y = self.encode_y(y)\n",
    "        \n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            validation_data = (self.preprocess(validation_data[0]), self.encode_y(validation_data[1]))\n",
    "        \n",
    "        return self.model.fit(X, y, *args, validation_data=validation_data, **kwargs)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        mask = X.str.split(', ').map(lambda d: len(d) > 2 or (len(d) == 1 and d[0] != '' and d[0] != ' '))\n",
    "        X = self.preprocess(X)\n",
    "        preds = self.model.predict(X)\n",
    "        preds[~mask] = 0\n",
    "        return preds\n",
    "    \n",
    "    def encode_y(self, y):\n",
    "        if self.encoder is None:\n",
    "            self.classes = np.unique(y)\n",
    "            print(self.classes)\n",
    "            self.encoder = OneHotEncoder(handle_unknown='ignore')#, categories=self.classes)\n",
    "            self.encoder.fit(pd.DataFrame(y))\n",
    "            \n",
    "            \n",
    "        return self.encoder.transform(pd.DataFrame(y)).toarray()\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        y = self.encode_y(y)\n",
    "        preds = self.predict(X)\n",
    "        \n",
    "        d = {\n",
    "            'MSE': ((y - preds) ** 2).mean(),\n",
    "            'MAE': np.abs((y - preds)).mean(),\n",
    "            'accuracy': sum(np.argmax(preds, axis=1) == np.argmax(y, axis=1)) / len(y)\n",
    "        }\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def _find_indices(self, values):\n",
    "        columns = self.keys.flatten()\n",
    "        inds = np.array([np.where(columns == searchval)[0] for searchval in values if searchval in self.keys]).flatten()\n",
    "        #print('values:', values)\n",
    "        #print('columns:', columns.shape)\n",
    "        #print('inds:', inds)\n",
    "        return inds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5                        üé∂\n",
       "17              ü§¨, üßø, üßø, üßø\n",
       "18                 ‚úã, ‚úã, ‚úã\n",
       "20                 üò®, üò±, üò±\n",
       "30                      üáÆüá≥\n",
       "32                      üáÆüá≥\n",
       "34                 üòÇ, üòÇ, üòÇ\n",
       "36                       ü•≤\n",
       "39             ‚úäüèª, ‚ô•, ü•∫, üßø\n",
       "40                       üåö\n",
       "45                 üò≠, üò≠, üò≠\n",
       "56                       üòî\n",
       "60                       ü§ç\n",
       "63                       ü¶å\n",
       "68              üòÇ, üòÇ, üòÇ, üòÇ\n",
       "73           üò≠, üò≠, üò≠, üò≠, üò≠\n",
       "74                       ü§≤\n",
       "76        üöÄ, üöÄ, üìÜ, üëë, üëë, üöÄ\n",
       "81                       ‚ò∫\n",
       "84                 üëè, üëè, üëè\n",
       "92                       ü´Ä\n",
       "93                       üíå\n",
       "96                       ‚ù§\n",
       "98                       ‚ò∫\n",
       "100              ü§∑\\u200d‚ôÄÔ∏è\n",
       "101    üò≠, üò≠, üò≠, üò≠, üò≠, üò≠, ‚ù§\n",
       "102                     üáÆüá≥\n",
       "106             ü§∑üèΩ\\u200d‚ôÄÔ∏è\n",
       "108                üòò, ‚ù§, ‚ù§\n",
       "109                      üòÇ\n",
       "110                      üåö\n",
       "112                ‚úã, ‚úã, ‚úã\n",
       "115                üéâ, üéâ, üéâ\n",
       "Name: emoi, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = emojis.str.split(', ').map(lambda d: len(d) > 2 or (len(d) == 1 and d[0] != '' and d[0] != ' '))\n",
    "emojis[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.split('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disappointed' 'happy' 'sad']\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 0.6888 - acc: 0.3333 - val_loss: 0.6874 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6781 - acc: 0.3939 - val_loss: 0.6811 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6630 - acc: 0.4242 - val_loss: 0.6738 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6497 - acc: 0.4242 - val_loss: 0.6654 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6375 - acc: 0.3939 - val_loss: 0.6557 - val_acc: 0.2333\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6204 - acc: 0.3939 - val_loss: 0.6450 - val_acc: 0.2333\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6016 - acc: 0.3939 - val_loss: 0.6335 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5994 - acc: 0.3939 - val_loss: 0.6216 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5493 - acc: 0.3939 - val_loss: 0.6101 - val_acc: 0.2333\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5636 - acc: 0.3939 - val_loss: 0.6005 - val_acc: 0.2333\n"
     ]
    }
   ],
   "source": [
    "emoji_model = EmojiModel('emoji_data/UNICODE_EMOJI_ALIAS.pkl')\n",
    "emojis_test = df_test['emoi'].str.strip('[]').str.replace(\"'\", '').str.lower()\n",
    "emoji_model.fit(emojis, y=df_train['label'], batch_size=16, epochs=10, validation_data=(emojis_test, df_test['label']))\n",
    "\n",
    "emoji_preds = emoji_model.predict(emojis)\n",
    "\n",
    "score = emoji_model.evaluate(emojis_test, df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2389544735940867, 'MAE': 0.25668826488157115, 'accuracy': 0.4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import fer\n",
    "import requests\n",
    "\n",
    "class ImageModel():\n",
    "    def __init__(self, prefix='im_'):\n",
    "        self.template = {'angry': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n",
    "        self.detector = fer.FER()\n",
    "        self.prefix = prefix\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for i, url in enumerate(X):\n",
    "            print(f'{i}: {url}')\n",
    "            if pd.isna(url):\n",
    "                preds.append(self.template.copy())\n",
    "                continue\n",
    "            img_data = requests.get(url).content\n",
    "            with open('./sample/images/temp.png', 'wb') as f:\n",
    "                f.write(img_data)\n",
    "            \n",
    "            bad_net_img = cv2.imread('./sample/images/temp.png')\n",
    "            try:\n",
    "                pred = self.detector.detect_emotions(bad_net_img)\n",
    "            except:\n",
    "                pred = []\n",
    "            if len(pred) > 0:\n",
    "                pred = [p['emotions'] for p in pred]\n",
    "                final_pred = self.template.copy()\n",
    "                for j, p in enumerate(pred, 1):\n",
    "                    for key in p.keys():\n",
    "                        final_pred[key] += p[key]\n",
    "                for key in p.keys():\n",
    "                    final_pred[key] /= j\n",
    "                        \n",
    "                print(final_pred)\n",
    "                preds.append(final_pred)\n",
    "            else:\n",
    "                preds.append(self.template.copy())\n",
    "                \n",
    "        df = pd.DataFrame(preds)\n",
    "        df.columns = [self.prefix + col for col in df.columns]\n",
    "        return df\n",
    "                \n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg\n",
      "{'angry': 0.02, 'disgust': 0.0, 'fear': 0.04, 'happy': 0.0, 'sad': 0.66, 'surprise': 0.0, 'neutral': 0.28}\n",
      "1: nan\n",
      "2: https://pbs.twimg.com/media/FJKQ1AlXIAMujwA.jpg\n",
      "{'angry': 0.075, 'disgust': 0.0, 'fear': 0.075, 'happy': 0.365, 'sad': 0.16, 'surprise': 0.09999999999999999, 'neutral': 0.22999999999999998}\n",
      "3: https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg\n",
      "4: https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg\n",
      "{'angry': 0.03, 'disgust': 0.0, 'fear': 0.68, 'happy': 0.0, 'sad': 0.04, 'surprise': 0.23, 'neutral': 0.01}\n",
      "5: https://video.twimg.com/ext_tw_video/1482346078628642822/pu/vid/320x320/rrNx4OG9HdEMAkiD.mp4?tag=12\n",
      "6: nan\n",
      "7: nan\n",
      "8: nan\n",
      "9: https://video.twimg.com/ext_tw_video/1325479794671296514/pu/vid/320x320/t67Lav6SVwiWtFJ3.mp4?tag=10\n",
      "10: nan\n",
      "11: nan\n",
      "12: nan\n",
      "13: https://pbs.twimg.com/media/FJJWa5IWYAAfUtz.jpg\n",
      "{'angry': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happy': 1.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n",
      "14: nan\n",
      "15: https://video.twimg.com/ext_tw_video/1482411001173757954/pu/pl/A29GkQzlSplvA8GA.m3u8?tag=12&container=fmp4\n",
      "16: nan\n",
      "17: nan\n",
      "18: nan\n",
      "19: nan\n",
      "20: nan\n",
      "21: nan\n",
      "22: nan\n",
      "23: nan\n",
      "24: nan\n",
      "25: nan\n",
      "26: https://pbs.twimg.com/media/FJJRS5HaQAUGvRk.jpg\n",
      "{'angry': 0.09000000000000001, 'disgust': 0.0, 'fear': 0.03166666666666667, 'happy': 0.4266666666666667, 'sad': 0.041666666666666664, 'surprise': 0.024999999999999998, 'neutral': 0.37833333333333335}\n",
      "27: nan\n",
      "28: nan\n",
      "29: nan\n",
      "30: https://pbs.twimg.com/media/FJJsAAgagAALu_m.jpg\n",
      "{'angry': 0.20333333333333334, 'disgust': 0.0, 'fear': 0.03, 'happy': 0.7066666666666667, 'sad': 0.01, 'surprise': 0.013333333333333334, 'neutral': 0.03333333333333333}\n",
      "31: nan\n",
      "32: https://pbs.twimg.com/media/FJJsAAgagAALu_m.jpg\n",
      "{'angry': 0.20333333333333334, 'disgust': 0.0, 'fear': 0.03, 'happy': 0.7066666666666667, 'sad': 0.01, 'surprise': 0.013333333333333334, 'neutral': 0.03333333333333333}\n",
      "33: nan\n",
      "34: nan\n",
      "35: nan\n",
      "36: https://video.twimg.com/ext_tw_video/1451328218968043526/pu/pl/6dapesvEYPoJKW84.m3u8?tag=12&container=fmp4\n",
      "37: https://pbs.twimg.com/media/FJHuW-haAAEe7hz.jpg\n",
      "38: nan\n",
      "39: https://pbs.twimg.com/media/FJJbKBeacAID1yF.jpg\n",
      "{'angry': 0.16166666666666665, 'disgust': 0.0, 'fear': 0.065, 'happy': 0.44166666666666665, 'sad': 0.125, 'surprise': 0.023333333333333334, 'neutral': 0.17833333333333334}\n",
      "40: nan\n",
      "41: https://video.twimg.com/tweet_video/FJHX5RaVEAEuBWq.mp4\n",
      "42: https://pbs.twimg.com/media/FJEgx61XIA49CS-.jpg\n",
      "43: nan\n",
      "44: https://pbs.twimg.com/media/FJKUmixXoAY7GKH.jpg\n",
      "45: https://video.twimg.com/ext_tw_video/1482401996200194052/pu/vid/320x556/rxDL3bkPx-qkxsr0.mp4?tag=12\n",
      "46: nan\n",
      "47: https://pbs.twimg.com/media/FJJdmrXWUAI3_mM.jpg\n",
      "48: https://pbs.twimg.com/media/FJIHq3nXsAEAOCu.jpg\n",
      "{'angry': 0.32, 'disgust': 0.01, 'fear': 0.07, 'happy': 0.21, 'sad': 0.32, 'surprise': 0.03, 'neutral': 0.04}\n",
      "49: nan\n",
      "50: nan\n",
      "51: nan\n",
      "52: nan\n",
      "53: https://pbs.twimg.com/media/FJJsQA0XEAg0FYk.jpg\n",
      "{'angry': 0.02, 'disgust': 0.0, 'fear': 0.07, 'happy': 0.0, 'sad': 0.11, 'surprise': 0.01, 'neutral': 0.79}\n",
      "54: https://pbs.twimg.com/media/FJKUy7GXEAIUR73.jpg\n",
      "55: nan\n",
      "56: nan\n",
      "57: https://video.twimg.com/tweet_video/FJKQQ5RWYAMl3IY.mp4\n",
      "58: nan\n",
      "59: https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg\n",
      "60: https://pbs.twimg.com/media/FJJS-7KXEAY9wZ_.jpg\n",
      "{'angry': 0.01, 'disgust': 0.0, 'fear': 0.02, 'happy': 0.13, 'sad': 0.05, 'surprise': 0.0, 'neutral': 0.78}\n",
      "61: https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg\n",
      "{'angry': 0.03, 'disgust': 0.0, 'fear': 0.68, 'happy': 0.0, 'sad': 0.04, 'surprise': 0.23, 'neutral': 0.01}\n",
      "62: nan\n",
      "63: https://video.twimg.com/ext_tw_video/1482394961647902725/pu/vid/480x600/qpSKE7IouoK0Pu_b.mp4?tag=12\n",
      "64: https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg\n",
      "{'angry': 0.02, 'disgust': 0.0, 'fear': 0.04, 'happy': 0.0, 'sad': 0.66, 'surprise': 0.0, 'neutral': 0.28}\n",
      "65: nan\n",
      "66: https://video.twimg.com/tweet_video/FJKTe0gXoAANSKF.mp4\n",
      "67: https://video.twimg.com/amplify_video/1482294295252324363/vid/320x320/Zr6Q4QAADHs4md7v.mp4?tag=14\n",
      "68: nan\n",
      "69: nan\n",
      "70: nan\n",
      "71: https://pbs.twimg.com/media/FJEgx61XIA49CS-.jpg\n",
      "72: https://pbs.twimg.com/media/FJJKfuMUUAMQxqV.jpg\n",
      "{'angry': 0.1, 'disgust': 0.0, 'fear': 0.24, 'happy': 0.04, 'sad': 0.29, 'surprise': 0.01, 'neutral': 0.32}\n",
      "73: nan\n",
      "74: nan\n",
      "75: nan\n",
      "76: https://pbs.twimg.com/media/FIldn0vVEAEkwEl.jpg\n",
      "{'angry': 0.37, 'disgust': 0.0, 'fear': 0.03, 'happy': 0.19, 'sad': 0.21, 'surprise': 0.03, 'neutral': 0.17}\n",
      "77: nan\n",
      "78: https://video.twimg.com/ext_tw_video/1482382689445777414/pu/vid/888x486/jSvOdwsyBePlmN4B.mp4?tag=12\n",
      "79: https://pbs.twimg.com/media/FJJZ9a9aAAQXwA0.jpg\n",
      "80: nan\n",
      "81: nan\n",
      "82: https://video.twimg.com/tweet_video/FJJ-N-EWUAMk6OE.mp4\n",
      "83: nan\n",
      "84: nan\n",
      "85: nan\n",
      "86: nan\n",
      "87: https://pbs.twimg.com/media/FJJXjpSWQAkEA7k.jpg\n",
      "88: nan\n",
      "89: https://video.twimg.com/ext_tw_video/1482028638585462785/pu/pl/844FF5Devg02L0BW.m3u8?tag=12&container=fmp4\n",
      "90: nan\n",
      "91: https://pbs.twimg.com/media/FJKLOV9XoAQOx0F.jpg\n",
      "{'angry': 0.115, 'disgust': 0.0, 'fear': 0.015, 'happy': 0.5599999999999999, 'sad': 0.125, 'surprise': 0.005, 'neutral': 0.185}\n",
      "92: https://video.twimg.com/ext_tw_video/1480409220461862919/pu/vid/938x720/mML3zzOfwepswnzq.mp4?tag=12\n",
      "93: https://pbs.twimg.com/media/FJEVv2IaMAAk4J4.jpg\n",
      "{'angry': 0.14166666666666666, 'disgust': 0.0, 'fear': 0.065, 'happy': 0.27999999999999997, 'sad': 0.08833333333333333, 'surprise': 0.02666666666666667, 'neutral': 0.40166666666666667}\n",
      "94: nan\n",
      "95: nan\n",
      "96: nan\n",
      "97: nan\n",
      "98: https://pbs.twimg.com/media/FJE5LEtWQAsTkPU.jpg\n",
      "{'angry': 0.07, 'disgust': 0.0, 'fear': 0.04, 'happy': 0.26, 'sad': 0.11, 'surprise': 0.15, 'neutral': 0.36}\n",
      "99: nan\n",
      "100: nan\n",
      "101: nan\n",
      "102: https://pbs.twimg.com/media/FJJsAAgagAALu_m.jpg\n",
      "{'angry': 0.20333333333333334, 'disgust': 0.0, 'fear': 0.03, 'happy': 0.7066666666666667, 'sad': 0.01, 'surprise': 0.013333333333333334, 'neutral': 0.03333333333333333}\n",
      "103: nan\n",
      "104: nan\n",
      "105: nan\n",
      "106: nan\n",
      "107: nan\n",
      "108: https://video.twimg.com/ext_tw_video/1482294494414635010/pu/vid/320x358/WR4sVEJL1-XeMuE1.mp4?tag=12\n",
      "109: nan\n",
      "110: nan\n",
      "111: https://pbs.twimg.com/media/FJI1_R7XIAAi8PL.jpg\n",
      "{'angry': 0.30500000000000005, 'disgust': 0.01, 'fear': 0.076, 'happy': 0.16699999999999998, 'sad': 0.23700000000000002, 'surprise': 0.025, 'neutral': 0.181}\n",
      "112: nan\n",
      "113: nan\n",
      "114: nan\n",
      "115: https://pbs.twimg.com/media/FJHf_tNVcAInEH1.jpg\n",
      "{'angry': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happy': 1.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n",
      "116: nan\n"
     ]
    }
   ],
   "source": [
    "image_model = ImageModel()\n",
    "image_preds = image_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @saarthaksing : @_dark_crusader And rakha also said correctly  that KK needs to come out of his shell and  play for himself not for beja. That‚Äôs why SK was angry with her because she was guiding Karan in the right direction. \\r\\n\\r\\n#KaranKundrra \\r\\n\\r\\nKARAN IS AN EMOTION'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[38, 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @hyungwon_india : #HYUNGWON\\r\\n#MONSTAX #MONSTA_X #Î™¨Ïä§ÌÉÄÏóëÏä§ #ÌòïÏõê #Ìë∏Î•¥Í≥†ÏïÑÎ¶ÑÎã§Ïö¥_ÌòïÏõêÏù¥ÏùòÌïòÎ£® \\r\\n#HBDtoHYUNGWON\\r\\n\\r\\n115 It was a happy and meaningful day with Monbebes &amp; MONSTA X , Hope you will always be surrounded by the people who love you and care for you. \\r\\nHappy Birthday once again Hyungwonie ü§ç https://t.co/JkkahZjSGC'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[60, 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>emoi</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Media URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @FranticKL : This is truly sad and most unk...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@imVkohli Sad to get this news but you are rhe...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad don't touch me https://t.co/ayNqChhXmP...</td>\n",
       "      <td>sad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJKQ1AlXIAMujwA.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AshaRangappa_ : STEP 5: Plan for all of th...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @_EL_PsyCongroo_ : #GenshinImpact #zhongxia...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[]</td>\n",
       "      <td>['GenshinImpact', 'zhongxiao', 'ÈçæÈ≠à']</td>\n",
       "      <td>https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label emoi  \\\n",
       "0  RT @FranticKL : This is truly sad and most unk...    sad   []   \n",
       "1  @imVkohli Sad to get this news but you are rhe...    sad   []   \n",
       "2  I'm sad don't touch me https://t.co/ayNqChhXmP...    sad   []   \n",
       "3  RT @AshaRangappa_ : STEP 5: Plan for all of th...  angry   []   \n",
       "4  RT @_EL_PsyCongroo_ : #GenshinImpact #zhongxia...  angry   []   \n",
       "\n",
       "                               hashtags  \\\n",
       "0                                    []   \n",
       "1                                    []   \n",
       "2                                    []   \n",
       "3                                    []   \n",
       "4  ['GenshinImpact', 'zhongxiao', 'ÈçæÈ≠à']   \n",
       "\n",
       "                                        Media URLs  \n",
       "0  https://pbs.twimg.com/media/FJJAdobagAEra9k.jpg  \n",
       "1                                              NaN  \n",
       "2  https://pbs.twimg.com/media/FJKQ1AlXIAMujwA.jpg  \n",
       "3  https://pbs.twimg.com/media/FJKCOhAWQAUEBCE.jpg  \n",
       "4  https://pbs.twimg.com/media/FG4kHYxagAAlDAl.jpg  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 13) (117, 13) (117, 4) (117, 7)\n"
     ]
    }
   ],
   "source": [
    "print(text_preds.shape, hashtag_preds.shape, emoji_preds.shape, image_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text_preds), type(hashtag_preds), type(emoji_preds), type(image_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([text_preds, hashtag_preds, pd.DataFrame(emoji_preds), image_preds], axis=1)\n",
    "df.to_excel('dataset_preds_all_models.xlsx')\n",
    "df.to_csv('dataset_preds_all_models.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
